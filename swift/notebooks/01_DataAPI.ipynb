{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing packages:\n",
      "\t.package(path: \"/home/alex/Desktop/ML/AI-Abstraction/swift/notebooks/exports/e_00_MNISTLoader\")\n",
      "\t\te_00_MNISTLoader\n",
      "With SwiftPM flags: []\n",
      "Working in: /tmp/tmpep3uyps0/swift-install\n",
      "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
      "[2/3] Merging module jupyterInstalledPackages\n",
      "Initializing Swift...\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%install-location $cwd/installed-packages\n",
    "%install '.package(path: \"$cwd/exports/e_00_MNISTLoader\")' e_00_MNISTLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TensorFlow\n",
    "import e_00_MNISTLoader\n",
    "\n",
    "#if canImport(PythonKit)\n",
    "    import PythonKit\n",
    "#else\n",
    "    import Python\n",
    "#endif\n",
    "\n",
    "%include \"EnableIPythonDisplay.swift\"\n",
    "IPythonDisplay.shell.enable_matplotlib(\"inline\")\n",
    "\n",
    "let plt = Python.import(\"matplotlib.pyplot\")\n",
    "\n",
    "func plotMNIST<T : NumpyScalarCompatible>(x : Tensor<T>) {\n",
    "    let img = x.makeNumpyArray().reshape(28, 28)\n",
    "    plt.figure(figsize: [5, 5])\n",
    "    plt.show(\n",
    "        plt.imshow(img, cmap: \"cool\")\n",
    "    )   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "let (xTrain, yTrain, xValid, yValid) = loadMNIST(path: MNISTPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "public struct DatasetV2<Tx : TensorFlowScalar, Ty : TensorFlowScalar> {\n",
    "    \n",
    "    public typealias XData = Tensor<Tx>\n",
    "    public typealias YData = Tensor<Ty>\n",
    "    \n",
    "    let x : XData\n",
    "    let y : YData\n",
    "    let count : Int\n",
    "    \n",
    "    public init(x xIn: XData, y yIn: YData) {\n",
    "        (x, y) = (xIn, yIn)\n",
    "        count = x.shape[0]\n",
    "    }\n",
    "    \n",
    "    subscript(_ i: Int) -> (XData, YData) {\n",
    "        return (x[i], y[i])\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "public struct DataLoader<Tx : TensorFlowScalar, Ty : TensorFlowScalar> {\n",
    "    \n",
    "    public typealias DS = DatasetV2<Tx, Ty>\n",
    "    \n",
    "    let dataset   : DS\n",
    "    let batchSize : Int\n",
    "    let shuffle   : Bool\n",
    "    \n",
    "    public init(dataset ds: DS, batchSize bs: Int, shuffle shuf: Bool = false) {\n",
    "        (dataset, batchSize, shuffle) = (ds, bs, shuf)\n",
    "    }\n",
    "    \n",
    "    public func inBatches() -> ([Tensor<Tx>], [Tensor<Ty>]) {\n",
    "        let numBatches = [dataset.count / batchSize]\n",
    "        let lastBatchSize = Tensor([Int32(dataset.count % batchSize)])\n",
    "\n",
    "        let splits = Tensor<Int32>([Int32(batchSize)])\n",
    "                        .tiled(multiples: numBatches)\n",
    "                        .concatenated(with: lastBatchSize)   \n",
    "        \n",
    "        let parts = (dataset.x.split(sizes: splits, alongAxis: 0), dataset.y.split(sizes: splits, alongAxis: 0))\n",
    "        \n",
    "        return parts\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var dataset = DatasetV2(x: xTrain, y: yTrain)\n",
    "dataset.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotMNIST(x: dataset[0].0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "var dataLoader = DataLoader(dataset: dataset, batchSize: 64)\n",
    "let batches = dataLoader.inBatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// let hiddenSize: Int = 50\n",
    "\n",
    "// struct SequentialModel<T: TensorFlowScalar> : Layer {\n",
    "//     var layers = [\n",
    "//       Dense<T>(inputSize: 4, outputSize: hiddenSize, activation: relu),\n",
    "//       Dense<T>(inputSize: hiddenSize, outputSize: hiddenSize, activation: relu),\n",
    "//       Dense<T>(inputSize: hiddenSize, outputSize: 3)\n",
    "//    ]\n",
    "//     // var layer1 = Dense<Float>(inputSize: 4, outputSize: hiddenSize, activation: relu)\n",
    "//     // var layer2 = Dense<Float>(inputSize: hiddenSize, outputSize: hiddenSize, activation: relu)\n",
    "//     // var layer3 = Dense<Float>(inputSize: hiddenSize, outputSize: 3)\n",
    "    \n",
    "//     @differentiable\n",
    "//     func callAsFunction(_ input: Tensor<T>) -> Tensor<T> {\n",
    "//       return forward(input)\n",
    "//     }\n",
    "\n",
    "//     @differentiable\n",
    "//     func forward(_ input: Tensor<T>, _ i: Int = 0) -> Tensor<T> {\n",
    "//       if i == layers.count-1 {\n",
    "//         return layers[i](input)\n",
    "//       } else {\n",
    "//         return forward(layers[i](input), i+1)\n",
    "//       }\n",
    "//     }\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "let hiddenSize: Int = 50\n",
    "struct IrisModel: Layer {\n",
    "    var layer1 = Dense<Float>(inputSize: 784, outputSize: hiddenSize, activation: relu)\n",
    "    var layer2 = Dense<Float>(inputSize: hiddenSize, outputSize: hiddenSize, activation: relu)\n",
    "    var layer3 = Dense<Float>(inputSize: hiddenSize, outputSize: 10)\n",
    "    \n",
    "    @differentiable\n",
    "    func callAsFunction(_ input: Tensor<Float>) -> Tensor<Float> {\n",
    "        return input.sequenced(through: layer1, layer2, layer3)\n",
    "    }\n",
    "}\n",
    "\n",
    "var model = IrisModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.513113\n",
      "Current loss: 0.34544513\n",
      "Current loss: 0.5885688\n",
      "Current loss: 0.4210691\n",
      "Current loss: 0.3851347\n",
      "Current loss: 0.2701551\n",
      "Current loss: 0.40246576\n",
      "Current loss: 0.5511909\n",
      "Current loss: 0.4075188\n",
      "Current loss: 0.6296403\n",
      "Current loss: 0.43474358\n",
      "Current loss: 0.38124093\n",
      "Current loss: 0.4195974\n",
      "Current loss: 0.6266251\n",
      "Current loss: 0.57821697\n",
      "Current loss: 0.49760997\n",
      "Current loss: 0.67253214\n",
      "Current loss: 0.722686\n",
      "Current loss: 0.27149516\n",
      "Current loss: 0.6742519\n",
      "Current loss: 0.4519796\n",
      "Current loss: 0.6525893\n",
      "Current loss: 0.39452732\n",
      "Current loss: 0.41823786\n",
      "Current loss: 0.49471003\n",
      "Current loss: 0.43321612\n",
      "Current loss: 0.3268866\n",
      "Current loss: 0.36025512\n",
      "Current loss: 0.3985387\n",
      "Current loss: 0.3189929\n",
      "Current loss: 0.34022895\n",
      "Current loss: 0.4115391\n",
      "Current loss: 0.36645052\n",
      "Current loss: 0.30113798\n",
      "Current loss: 0.4144564\n",
      "Current loss: 0.31871873\n",
      "Current loss: 0.3068427\n",
      "Current loss: 0.5920725\n",
      "Current loss: 0.348953\n",
      "Current loss: 0.35730678\n",
      "Current loss: 0.31760213\n",
      "Current loss: 0.49381092\n",
      "Current loss: 0.38088143\n",
      "Current loss: 0.470609\n",
      "Current loss: 0.29439697\n",
      "Current loss: 0.42652386\n",
      "Current loss: 0.40309146\n",
      "Current loss: 0.585923\n",
      "Current loss: 0.356398\n",
      "Current loss: 0.34636134\n",
      "Current loss: 0.38863033\n",
      "Current loss: 0.4341325\n",
      "Current loss: 0.456785\n",
      "Current loss: 0.38923472\n",
      "Current loss: 0.43240336\n",
      "Current loss: 0.4810471\n",
      "Current loss: 0.30720007\n",
      "Current loss: 0.52512443\n",
      "Current loss: 0.47331485\n",
      "Current loss: 0.4761097\n",
      "Current loss: 0.3013245\n",
      "Current loss: 0.25264198\n",
      "Current loss: 0.3540746\n",
      "Current loss: 0.45806065\n",
      "Current loss: 0.52956593\n",
      "Current loss: 0.45317394\n",
      "Current loss: 0.48056877\n",
      "Current loss: 0.36565912\n",
      "Current loss: 0.36710292\n",
      "Current loss: 0.3860754\n",
      "Current loss: 0.38063103\n",
      "Current loss: 0.25377458\n",
      "Current loss: 0.48669437\n",
      "Current loss: 0.37250453\n",
      "Current loss: 0.47790948\n",
      "Current loss: 0.4256639\n",
      "Current loss: 0.39170694\n",
      "Current loss: 0.54723513\n",
      "Current loss: 0.35654998\n",
      "Current loss: 0.4701108\n",
      "Current loss: 0.6690857\n",
      "Current loss: 0.30784044\n",
      "Current loss: 0.52388\n",
      "Current loss: 0.37686047\n",
      "Current loss: 0.43595698\n",
      "Current loss: 0.23278442\n",
      "Current loss: 0.4140362\n",
      "Current loss: 0.40706792\n",
      "Current loss: 0.37202597\n",
      "Current loss: 0.42993492\n",
      "Current loss: 0.34527427\n",
      "Current loss: 0.53880656\n",
      "Current loss: 0.35571828\n",
      "Current loss: 0.36079335\n",
      "Current loss: 0.25893795\n",
      "Current loss: 0.3772095\n",
      "Current loss: 0.3269551\n",
      "Current loss: 0.38138604\n",
      "Current loss: 0.35312736\n",
      "Current loss: 0.30976695\n",
      "Current loss: 0.3569954\n",
      "Current loss: 0.39706212\n",
      "Current loss: 0.23977366\n",
      "Current loss: 0.27922282\n",
      "Current loss: 0.37336352\n",
      "Current loss: 0.32245383\n",
      "Current loss: 0.5617514\n",
      "Current loss: 0.47797298\n",
      "Current loss: 0.47816962\n",
      "Current loss: 0.6543774\n",
      "Current loss: 0.34073448\n",
      "Current loss: 0.43242472\n",
      "Current loss: 0.589823\n",
      "Current loss: 0.6526768\n",
      "Current loss: 0.5872388\n",
      "Current loss: 0.37702304\n",
      "Current loss: 0.36962658\n",
      "Current loss: 0.5252859\n",
      "Current loss: 0.26611727\n",
      "Current loss: 0.5096569\n",
      "Current loss: 0.383362\n",
      "Current loss: 0.43026367\n",
      "Current loss: 0.5479983\n",
      "Current loss: 0.5732349\n",
      "Current loss: 0.423544\n",
      "Current loss: 0.5166523\n",
      "Current loss: 0.49308985\n",
      "Current loss: 0.3102413\n",
      "Current loss: 0.6583736\n",
      "Current loss: 0.5042901\n",
      "Current loss: 0.38510317\n",
      "Current loss: 0.5405233\n",
      "Current loss: 0.46879312\n",
      "Current loss: 0.3202947\n",
      "Current loss: 0.3241553\n",
      "Current loss: 0.7178114\n",
      "Current loss: 0.7886319\n",
      "Current loss: 0.5133139\n",
      "Current loss: 0.7812352\n",
      "Current loss: 0.50981927\n",
      "Current loss: 0.3090126\n",
      "Current loss: 0.23144536\n",
      "Current loss: 0.585822\n",
      "Current loss: 0.30329388\n",
      "Current loss: 0.58689225\n",
      "Current loss: 0.4399191\n",
      "Current loss: 0.48703068\n",
      "Current loss: 0.55193436\n",
      "Current loss: 0.33734685\n",
      "Current loss: 0.480817\n",
      "Current loss: 0.4173292\n",
      "Current loss: 0.22745803\n",
      "Current loss: 0.5498264\n",
      "Current loss: 0.27076045\n",
      "Current loss: 0.2616258\n",
      "Current loss: 0.36149162\n",
      "Current loss: 0.44485497\n",
      "Current loss: 0.32499295\n",
      "Current loss: 0.29350945\n",
      "Current loss: 0.5309222\n",
      "Current loss: 0.47030175\n",
      "Current loss: 0.26489317\n",
      "Current loss: 0.22249094\n",
      "Current loss: 0.29459724\n",
      "Current loss: 0.21734692\n",
      "Current loss: 0.27105474\n",
      "Current loss: 0.33365837\n",
      "Current loss: 0.45975548\n",
      "Current loss: 0.43102458\n",
      "Current loss: 0.35109156\n",
      "Current loss: 0.33472198\n",
      "Current loss: 0.34332395\n",
      "Current loss: 0.32205853\n",
      "Current loss: 0.37662935\n",
      "Current loss: 0.27914703\n",
      "Current loss: 0.54408693\n",
      "Current loss: 0.2937057\n",
      "Current loss: 0.35684967\n",
      "Current loss: 0.28028488\n",
      "Current loss: 0.39830405\n",
      "Current loss: 0.65739876\n",
      "Current loss: 0.5705333\n",
      "Current loss: 0.61202216\n",
      "Current loss: 0.60000306\n",
      "Current loss: 0.3572453\n",
      "Current loss: 0.48749056\n",
      "Current loss: 0.3285085\n",
      "Current loss: 0.3529101\n",
      "Current loss: 0.38986242\n",
      "Current loss: 0.2782934\n",
      "Current loss: 0.45981407\n",
      "Current loss: 0.35866344\n",
      "Current loss: 0.36530024\n",
      "Current loss: 0.45986515\n",
      "Current loss: 0.5139128\n",
      "Current loss: 0.4771797\n",
      "Current loss: 0.7943754\n",
      "Current loss: 0.6134798\n",
      "Current loss: 0.46336895\n",
      "Current loss: 0.47835922\n",
      "Current loss: 0.35144758\n",
      "Current loss: 0.3096316\n",
      "Current loss: 0.5719472\n",
      "Current loss: 0.7187964\n",
      "Current loss: 0.6849855\n",
      "Current loss: 0.60534143\n",
      "Current loss: 0.32450667\n",
      "Current loss: 0.34493136\n",
      "Current loss: 0.39210343\n",
      "Current loss: 0.3381463\n",
      "Current loss: 0.29011437\n",
      "Current loss: 0.345423\n",
      "Current loss: 0.1883913\n",
      "Current loss: 0.56582195\n",
      "Current loss: 0.54223007\n",
      "Current loss: 0.30749774\n",
      "Current loss: 0.43182215\n",
      "Current loss: 0.46192467\n",
      "Current loss: 0.8002909\n",
      "Current loss: 0.4445156\n",
      "Current loss: 0.50998205\n",
      "Current loss: 0.412841\n",
      "Current loss: 0.42023346\n",
      "Current loss: 0.5257691\n",
      "Current loss: 0.70773304\n",
      "Current loss: 0.3968292\n",
      "Current loss: 0.4282709\n",
      "Current loss: 0.5151219\n",
      "Current loss: 0.5807158\n",
      "Current loss: 0.57963246\n",
      "Current loss: 0.6662041\n",
      "Current loss: 0.7255349\n",
      "Current loss: 0.37286794\n",
      "Current loss: 0.31449473\n",
      "Current loss: 0.3180542\n",
      "Current loss: 0.26303905\n",
      "Current loss: 0.5850855\n",
      "Current loss: 0.3899945\n",
      "Current loss: 0.41865256\n",
      "Current loss: 0.31438875\n",
      "Current loss: 0.3534692\n",
      "Current loss: 0.30977988\n",
      "Current loss: 0.45906258\n",
      "Current loss: 0.33977866\n",
      "Current loss: 0.33079654\n",
      "Current loss: 0.54215014\n",
      "Current loss: 0.55701387\n",
      "Current loss: 0.47224697\n",
      "Current loss: 0.40668392\n",
      "Current loss: 0.6534084\n",
      "Current loss: 0.60743254\n",
      "Current loss: 0.39449316\n",
      "Current loss: 0.30709508\n",
      "Current loss: 0.38642204\n",
      "Current loss: 0.30833557\n",
      "Current loss: 0.3813252\n",
      "Current loss: 0.3087501\n",
      "Current loss: 0.357824\n",
      "Current loss: 0.41353807\n",
      "Current loss: 0.31716022\n",
      "Current loss: 0.484629\n",
      "Current loss: 0.46739754\n",
      "Current loss: 0.5457003\n",
      "Current loss: 0.3696869\n",
      "Current loss: 0.4114919\n",
      "Current loss: 0.5699786\n",
      "Current loss: 0.4084798\n",
      "Current loss: 0.42481047\n",
      "Current loss: 0.51649046\n",
      "Current loss: 0.47790277\n",
      "Current loss: 0.2671054\n",
      "Current loss: 0.4865376\n",
      "Current loss: 0.3132804\n",
      "Current loss: 0.461523\n",
      "Current loss: 0.7765858\n",
      "Current loss: 0.39277247\n",
      "Current loss: 0.611475\n",
      "Current loss: 0.47995844\n",
      "Current loss: 0.5207106\n",
      "Current loss: 0.48124832\n",
      "Current loss: 0.32743645\n",
      "Current loss: 0.35391116\n",
      "Current loss: 0.37153754\n",
      "Current loss: 0.23880036\n",
      "Current loss: 0.22735032\n",
      "Current loss: 0.2912074\n",
      "Current loss: 0.33739445\n",
      "Current loss: 0.4528877\n",
      "Current loss: 0.40193456\n",
      "Current loss: 0.30260247\n",
      "Current loss: 0.47381493\n",
      "Current loss: 0.38648665\n",
      "Current loss: 0.4565553\n",
      "Current loss: 0.23907349\n",
      "Current loss: 0.39605147\n",
      "Current loss: 0.2687396\n",
      "Current loss: 0.30528054\n",
      "Current loss: 0.3921718\n",
      "Current loss: 0.46649542\n",
      "Current loss: 0.42887336\n",
      "Current loss: 0.4762877\n",
      "Current loss: 0.3690936\n",
      "Current loss: 0.383128\n",
      "Current loss: 0.36369193\n",
      "Current loss: 0.38946444\n",
      "Current loss: 0.42263672\n",
      "Current loss: 0.28810143\n",
      "Current loss: 0.1875599\n",
      "Current loss: 0.17669208\n",
      "Current loss: 0.49851474\n",
      "Current loss: 0.30495965\n",
      "Current loss: 0.38774785\n",
      "Current loss: 0.4373339\n",
      "Current loss: 0.49890304\n",
      "Current loss: 0.32845843\n",
      "Current loss: 0.62163055\n",
      "Current loss: 0.38530877\n",
      "Current loss: 0.39669532\n",
      "Current loss: 0.26103073\n",
      "Current loss: 0.23660907\n",
      "Current loss: 0.25264013\n",
      "Current loss: 0.43507037\n",
      "Current loss: 0.33430696\n",
      "Current loss: 0.55987835\n",
      "Current loss: 0.45301703\n",
      "Current loss: 0.4792463\n",
      "Current loss: 0.56580913\n",
      "Current loss: 0.6565896\n",
      "Current loss: 0.4347605\n",
      "Current loss: 0.3696832\n",
      "Current loss: 0.3030665\n",
      "Current loss: 0.25645044\n",
      "Current loss: 0.25010452\n",
      "Current loss: 0.37071592\n",
      "Current loss: 0.3669808\n",
      "Current loss: 0.19139805\n",
      "Current loss: 0.3543584\n",
      "Current loss: 0.5394392\n",
      "Current loss: 0.30052155\n",
      "Current loss: 0.3767177\n",
      "Current loss: 0.13098451\n",
      "Current loss: 0.16664454\n",
      "Current loss: 0.32882658\n",
      "Current loss: 0.32322508\n",
      "Current loss: 0.26769215\n",
      "Current loss: 0.5972891\n",
      "Current loss: 0.45842648\n",
      "Current loss: 0.44094363\n",
      "Current loss: 0.39532298\n",
      "Current loss: 0.17724764\n",
      "Current loss: 0.31193233\n",
      "Current loss: 0.7089586\n",
      "Current loss: 0.6072173\n",
      "Current loss: 0.5252126\n",
      "Current loss: 0.34319887\n",
      "Current loss: 0.37780374\n",
      "Current loss: 0.32575703\n",
      "Current loss: 0.24776655\n",
      "Current loss: 0.1632167\n",
      "Current loss: 0.3484645\n",
      "Current loss: 0.4357901\n",
      "Current loss: 0.42183587\n",
      "Current loss: 0.40724045\n",
      "Current loss: 0.24755394\n",
      "Current loss: 0.30265749\n",
      "Current loss: 0.3032048\n",
      "Current loss: 0.38113958\n",
      "Current loss: 0.32492357\n",
      "Current loss: 0.34111786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.36753175\n",
      "Current loss: 0.63191605\n",
      "Current loss: 0.2616218\n",
      "Current loss: 0.46519616\n",
      "Current loss: 0.36336526\n",
      "Current loss: 0.49882394\n",
      "Current loss: 0.43079698\n",
      "Current loss: 0.28710538\n",
      "Current loss: 0.28911868\n",
      "Current loss: 0.467428\n",
      "Current loss: 0.5062867\n",
      "Current loss: 0.3421405\n",
      "Current loss: 0.3318203\n",
      "Current loss: 0.42812636\n",
      "Current loss: 0.49874866\n",
      "Current loss: 0.5621971\n",
      "Current loss: 0.44528964\n",
      "Current loss: 0.5055601\n",
      "Current loss: 0.4923639\n",
      "Current loss: 0.28516713\n",
      "Current loss: 0.45915985\n",
      "Current loss: 0.41597766\n",
      "Current loss: 0.24712676\n",
      "Current loss: 0.42185253\n",
      "Current loss: 0.33722723\n",
      "Current loss: 0.3767145\n",
      "Current loss: 0.54836696\n",
      "Current loss: 0.20818855\n",
      "Current loss: 0.21724457\n",
      "Current loss: 0.30481523\n",
      "Current loss: 0.37569577\n",
      "Current loss: 0.30277348\n",
      "Current loss: 0.27751085\n",
      "Current loss: 0.304625\n",
      "Current loss: 0.51385856\n",
      "Current loss: 0.2947647\n",
      "Current loss: 0.37088776\n",
      "Current loss: 0.24970554\n",
      "Current loss: 0.32912675\n",
      "Current loss: 0.25895548\n",
      "Current loss: 0.2524763\n",
      "Current loss: 0.47031695\n",
      "Current loss: 0.38461733\n",
      "Current loss: 0.64049804\n",
      "Current loss: 0.52555084\n",
      "Current loss: 0.4767098\n",
      "Current loss: 0.4745861\n",
      "Current loss: 0.5879649\n",
      "Current loss: 0.6032673\n",
      "Current loss: 0.43062907\n",
      "Current loss: 0.32586905\n",
      "Current loss: 0.48418278\n",
      "Current loss: 0.26717567\n",
      "Current loss: 0.23486257\n",
      "Current loss: 0.29051197\n",
      "Current loss: 0.56967\n",
      "Current loss: 0.4463625\n",
      "Current loss: 0.34641358\n",
      "Current loss: 0.3045805\n",
      "Current loss: 0.36088407\n",
      "Current loss: 0.42041838\n",
      "Current loss: 0.30018017\n",
      "Current loss: 0.40709808\n",
      "Current loss: 0.38042492\n",
      "Current loss: 0.36393672\n",
      "Current loss: 0.4852571\n",
      "Current loss: 0.29023784\n",
      "Current loss: 0.28087157\n",
      "Current loss: 0.25229853\n",
      "Current loss: 0.21226645\n",
      "Current loss: 0.29044765\n",
      "Current loss: 0.3699644\n",
      "Current loss: 0.33790648\n",
      "Current loss: 0.24615794\n",
      "Current loss: 0.64801127\n",
      "Current loss: 0.28672192\n",
      "Current loss: 0.4024655\n",
      "Current loss: 0.3466032\n",
      "Current loss: 0.75905514\n",
      "Current loss: 0.3786199\n",
      "Current loss: 0.27575377\n",
      "Current loss: 0.24545464\n",
      "Current loss: 0.21142286\n",
      "Current loss: 0.33199516\n",
      "Current loss: 0.26790956\n",
      "Current loss: 0.52900076\n",
      "Current loss: 0.59176224\n",
      "Current loss: 0.45889676\n",
      "Current loss: 0.39871716\n",
      "Current loss: 0.35100633\n",
      "Current loss: 0.41051802\n",
      "Current loss: 0.31827092\n",
      "Current loss: 0.33284935\n",
      "Current loss: 0.29117256\n",
      "Current loss: 0.46580374\n",
      "Current loss: 0.5439899\n",
      "Current loss: 0.32530317\n",
      "Current loss: 0.56927973\n",
      "Current loss: 0.56627584\n",
      "Current loss: 0.5447733\n",
      "Current loss: 0.42238232\n",
      "Current loss: 0.5355979\n",
      "Current loss: 0.5990068\n",
      "Current loss: 0.4296943\n",
      "Current loss: 0.2962748\n",
      "Current loss: 0.2190544\n",
      "Current loss: 0.40736714\n",
      "Current loss: 0.42350954\n",
      "Current loss: 0.38318908\n",
      "Current loss: 0.5789063\n",
      "Current loss: 0.42505735\n",
      "Current loss: 0.45725536\n",
      "Current loss: 0.37705567\n",
      "Current loss: 0.5586115\n",
      "Current loss: 0.3985165\n",
      "Current loss: 0.41684243\n",
      "Current loss: 0.35522103\n",
      "Current loss: 0.5152561\n",
      "Current loss: 0.54729486\n",
      "Current loss: 0.48628005\n",
      "Current loss: 0.7399422\n",
      "Current loss: 0.5231376\n",
      "Current loss: 0.4352807\n",
      "Current loss: 0.27394468\n",
      "Current loss: 0.3796332\n",
      "Current loss: 0.5931215\n",
      "Current loss: 0.6681888\n",
      "Current loss: 0.5226624\n",
      "Current loss: 0.3433913\n",
      "Current loss: 0.43517214\n",
      "Current loss: 0.39600164\n",
      "Current loss: 0.3638021\n",
      "Current loss: 0.43604177\n",
      "Current loss: 0.44684803\n",
      "Current loss: 0.47422853\n",
      "Current loss: 0.49706253\n",
      "Current loss: 0.5619507\n",
      "Current loss: 0.6290796\n",
      "Current loss: 0.5706334\n",
      "Current loss: 0.42093146\n",
      "Current loss: 0.17736259\n",
      "Current loss: 0.40611473\n",
      "Current loss: 0.34411335\n",
      "Current loss: 0.6110474\n",
      "Current loss: 0.2593215\n",
      "Current loss: 0.38470417\n",
      "Current loss: 0.2603031\n",
      "Current loss: 0.4806432\n",
      "Current loss: 0.27672982\n",
      "Current loss: 0.24816161\n",
      "Current loss: 0.412415\n",
      "Current loss: 0.3548261\n",
      "Current loss: 0.47163263\n",
      "Current loss: 0.42578262\n",
      "Current loss: 0.38481274\n",
      "Current loss: 0.3582632\n",
      "Current loss: 0.24449256\n",
      "Current loss: 0.21055657\n",
      "Current loss: 0.46096492\n",
      "Current loss: 0.19984943\n",
      "Current loss: 0.16279545\n",
      "Current loss: 0.18541297\n",
      "Current loss: 0.3370954\n",
      "Current loss: 0.34890723\n",
      "Current loss: 0.25437427\n",
      "Current loss: 0.2380468\n",
      "Current loss: 0.2289409\n",
      "Current loss: 0.25961122\n",
      "Current loss: 0.44461912\n",
      "Current loss: 0.459678\n",
      "Current loss: 0.49719965\n",
      "Current loss: 0.33944994\n",
      "Current loss: 0.49473485\n",
      "Current loss: 0.49449363\n",
      "Current loss: 0.41904306\n",
      "Current loss: 0.5808154\n",
      "Current loss: 0.38941947\n",
      "Current loss: 0.19981581\n",
      "Current loss: 0.33133036\n",
      "Current loss: 0.2737377\n",
      "Current loss: 0.34023726\n",
      "Current loss: 0.44085371\n",
      "Current loss: 0.27240747\n",
      "Current loss: 0.21897173\n",
      "Current loss: 0.29755056\n",
      "Current loss: 0.4539086\n",
      "Current loss: 0.26799816\n",
      "Current loss: 0.4384558\n",
      "Current loss: 0.33524773\n",
      "Current loss: 0.23935547\n",
      "Current loss: 0.24413994\n",
      "Current loss: 0.34316272\n",
      "Current loss: 0.36279863\n",
      "Current loss: 0.44100815\n",
      "Current loss: 0.37899536\n",
      "Current loss: 0.34985918\n",
      "Current loss: 0.3065249\n",
      "Current loss: 0.23267972\n",
      "Current loss: 0.18565422\n",
      "Current loss: 0.36240512\n",
      "Current loss: 0.38142768\n",
      "Current loss: 0.37132007\n",
      "Current loss: 0.2589572\n",
      "Current loss: 0.21589498\n",
      "Current loss: 0.20588832\n",
      "Current loss: 0.35314825\n",
      "Current loss: 0.33227602\n",
      "Current loss: 0.36072445\n",
      "Current loss: 0.19926952\n",
      "Current loss: 0.32798466\n",
      "Current loss: 0.45296788\n",
      "Current loss: 0.42282605\n",
      "Current loss: 0.29149267\n",
      "Current loss: 0.58995986\n",
      "Current loss: 0.666147\n",
      "Current loss: 0.8939972\n",
      "Current loss: 0.6098521\n",
      "Current loss: 0.45831537\n",
      "Current loss: 0.35617334\n",
      "Current loss: 0.31766385\n",
      "Current loss: 0.38879168\n",
      "Current loss: 0.36133063\n",
      "Current loss: 0.39684826\n",
      "Current loss: 0.34502023\n",
      "Current loss: 0.40243173\n",
      "Current loss: 0.37683168\n",
      "Current loss: 0.23556726\n",
      "Current loss: 0.262242\n",
      "Current loss: 0.43345818\n",
      "Current loss: 0.4008808\n",
      "Current loss: 0.43639126\n",
      "Current loss: 0.26337665\n",
      "Current loss: 0.43907264\n",
      "Current loss: 0.43787995\n",
      "Current loss: 0.504007\n",
      "Current loss: 0.39355773\n",
      "Current loss: 0.31533793\n",
      "Current loss: 0.26750326\n",
      "Current loss: 0.17924848\n",
      "Current loss: 0.20336157\n",
      "Current loss: 0.3612641\n",
      "Current loss: 0.19147334\n",
      "Current loss: 0.33736417\n",
      "Current loss: 0.2705117\n",
      "Current loss: 0.3052405\n",
      "Current loss: 0.86552656\n",
      "Current loss: 0.46013778\n",
      "Current loss: 0.60967416\n",
      "Current loss: 0.2905844\n",
      "Current loss: 0.2856006\n",
      "Current loss: 0.41158378\n",
      "Current loss: 0.33398628\n",
      "Current loss: 0.5341273\n",
      "Current loss: 0.37906882\n",
      "Current loss: 0.46766114\n",
      "Current loss: 0.43371361\n",
      "Current loss: 0.26042265\n",
      "Current loss: 0.3216369\n",
      "Current loss: 0.2947453\n",
      "Current loss: 0.34093958\n",
      "Current loss: 0.35246313\n",
      "Current loss: 0.2935663\n",
      "Current loss: 0.35352686\n",
      "Current loss: 0.42870638\n",
      "Current loss: 0.33180258\n",
      "Current loss: 0.34520206\n",
      "Current loss: 0.33254802\n",
      "Current loss: 0.36131677\n",
      "Current loss: 0.26184905\n",
      "Current loss: 0.22558987\n",
      "Current loss: 0.25076964\n",
      "Current loss: 0.4842489\n",
      "Current loss: 0.3116895\n",
      "Current loss: 0.3666089\n",
      "Current loss: 0.25226906\n",
      "Current loss: 0.49042535\n",
      "Current loss: 0.56470656\n",
      "Current loss: 0.44020426\n",
      "Current loss: 0.6006219\n",
      "Current loss: 0.39966333\n",
      "Current loss: 0.53681237\n",
      "Current loss: 0.33394518\n",
      "Current loss: 0.30311614\n",
      "Current loss: 0.45119756\n",
      "Current loss: 0.3194004\n",
      "Current loss: 0.30262643\n",
      "Current loss: 0.4118855\n",
      "Current loss: 0.49056545\n",
      "Current loss: 0.37347376\n",
      "Current loss: 0.43173778\n",
      "Current loss: 0.51556206\n",
      "Current loss: 0.33947304\n",
      "Current loss: 0.6370181\n",
      "Current loss: 0.40498954\n",
      "Current loss: 0.6324144\n",
      "Current loss: 0.5421735\n",
      "Current loss: 0.1900899\n",
      "Current loss: 0.3237045\n",
      "Current loss: 0.34284222\n",
      "Current loss: 0.36786675\n",
      "Current loss: 0.4135094\n",
      "Current loss: 0.43984225\n",
      "Current loss: 0.46236092\n",
      "Current loss: 0.4287556\n",
      "Current loss: 0.4629233\n",
      "Current loss: 0.21576628\n",
      "Current loss: 0.5150042\n",
      "Current loss: 0.13195539\n",
      "Current loss: 0.2538413\n",
      "Current loss: 0.22019677\n",
      "Current loss: 0.1942792\n",
      "Current loss: 0.3166622\n",
      "Current loss: 0.17156292\n",
      "Current loss: 0.4211373\n",
      "Current loss: 0.23998813\n",
      "Current loss: 0.4334947\n",
      "Current loss: 0.44279072\n",
      "Current loss: 0.44332\n",
      "Current loss: 0.33398357\n",
      "Current loss: 0.30868462\n",
      "Current loss: 0.57584935\n",
      "Current loss: 0.29123703\n",
      "Current loss: 0.49208772\n",
      "Current loss: 0.47052675\n",
      "Current loss: 0.41193053\n",
      "Current loss: 0.4116719\n",
      "Current loss: 0.3102269\n",
      "Current loss: 0.20961536\n",
      "Current loss: 0.2086551\n",
      "Current loss: 0.2529136\n",
      "Current loss: 0.34571764\n",
      "Current loss: 0.4669044\n",
      "Current loss: 0.42884094\n",
      "Current loss: 0.368527\n",
      "Current loss: 0.56224614\n",
      "Current loss: 0.40811393\n",
      "Current loss: 0.41815242\n",
      "Current loss: 0.3383844\n",
      "Current loss: 0.26881474\n",
      "Current loss: 0.19387531\n",
      "Current loss: 0.38082674\n",
      "Current loss: 0.6101153\n",
      "Current loss: 0.36191607\n",
      "Current loss: 0.44010717\n",
      "Current loss: 0.28023535\n",
      "Current loss: 0.27222013\n",
      "Current loss: 0.49082667\n",
      "Current loss: 0.42592055\n",
      "Current loss: 0.4344224\n",
      "Current loss: 0.41793483\n",
      "Current loss: 0.4167419\n",
      "Current loss: 0.43211272\n",
      "Current loss: 0.3673262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current loss: 0.47473875\n",
      "Current loss: 0.580036\n",
      "Current loss: 0.43909442\n",
      "Current loss: 0.47055686\n",
      "Current loss: 0.21205609\n",
      "Current loss: 0.28040686\n",
      "Current loss: 0.31346607\n",
      "Current loss: 0.19577368\n",
      "Current loss: 0.39686984\n",
      "Current loss: 0.19744423\n",
      "Current loss: 0.3112808\n",
      "Current loss: 0.30264962\n",
      "Current loss: 0.38736695\n",
      "Current loss: 0.2359173\n",
      "Current loss: 0.27390826\n",
      "Current loss: 0.372729\n",
      "Current loss: 0.4724331\n",
      "Current loss: 0.40120882\n",
      "Current loss: 0.325331\n",
      "Current loss: 0.455391\n",
      "Current loss: 0.21087123\n",
      "Current loss: 0.62325716\n",
      "Current loss: 0.29344764\n",
      "Current loss: 0.36635554\n",
      "Current loss: 0.37277016\n",
      "Current loss: 0.19635418\n",
      "Current loss: 0.497526\n",
      "Current loss: 0.4808696\n",
      "Current loss: 0.20826195\n",
      "Current loss: 0.269054\n",
      "Current loss: 0.18264593\n",
      "Current loss: 0.17874643\n",
      "Current loss: 0.27912217\n",
      "Current loss: 0.5539192\n",
      "Current loss: 0.29361638\n",
      "Current loss: 0.22745736\n",
      "Current loss: 0.37643194\n",
      "Current loss: 0.2676927\n",
      "Current loss: 0.27948698\n",
      "Current loss: 0.22519135\n",
      "Current loss: 0.20429352\n",
      "Current loss: 0.24455231\n",
      "Current loss: 0.5502552\n",
      "Current loss: 0.62938136\n",
      "Current loss: 0.5076977\n",
      "Current loss: 0.4015385\n",
      "Current loss: 0.53408396\n",
      "Current loss: 0.39174497\n",
      "Current loss: 0.22439347\n",
      "Current loss: 0.2481313\n",
      "Current loss: 0.37307078\n",
      "Current loss: 0.73355615\n",
      "Current loss: 0.6779069\n",
      "Current loss: 0.55251837\n",
      "Current loss: 0.34696525\n",
      "Current loss: 0.23138729\n",
      "Current loss: 0.36567205\n",
      "Current loss: 0.5469623\n",
      "Current loss: 0.34063748\n",
      "Current loss: 0.39805016\n",
      "Current loss: 0.41075933\n",
      "Current loss: 0.31476623\n",
      "Current loss: 0.6708082\n",
      "Current loss: 0.2920583\n",
      "Current loss: 0.5346073\n",
      "Current loss: 0.9550128\n",
      "Current loss: 0.31181866\n",
      "Current loss: 0.4109745\n",
      "Current loss: 0.51217115\n",
      "Current loss: 0.4564137\n",
      "Current loss: 0.45166343\n",
      "Current loss: 0.26559344\n",
      "Current loss: 0.28165865\n",
      "Current loss: 0.23460385\n",
      "Current loss: 0.17692155\n",
      "Current loss: 0.22541708\n",
      "Current loss: 0.23767832\n",
      "Current loss: 0.4158498\n",
      "Current loss: 0.349922\n",
      "Current loss: 0.4319144\n",
      "Current loss: 0.25162134\n",
      "Current loss: 0.2917947\n",
      "Current loss: 0.18661381\n",
      "Current loss: 0.3564974\n",
      "Current loss: 0.21465367\n",
      "Current loss: 0.23438418\n",
      "Current loss: 0.36767864\n",
      "Current loss: 0.18350144\n",
      "Current loss: 0.27907076\n",
      "Current loss: 0.3555399\n",
      "Current loss: 0.40835807\n",
      "Current loss: 0.45701724\n",
      "Current loss: 0.6562841\n",
      "Current loss: 0.38800186\n",
      "Current loss: 0.41922355\n",
      "Current loss: 0.2984076\n",
      "Current loss: 0.40787488\n",
      "Current loss: 0.23717229\n",
      "Current loss: 0.13414252\n",
      "Current loss: 0.25067955\n",
      "Current loss: 0.330103\n",
      "Current loss: 0.4793077\n",
      "Current loss: 0.5281909\n",
      "Current loss: 0.44146657\n",
      "Current loss: 0.62601817\n",
      "Current loss: 0.80452025\n",
      "Current loss: 0.36123976\n",
      "Current loss: 0.22804257\n",
      "Current loss: 0.4131007\n",
      "Current loss: 0.3838981\n",
      "Current loss: 0.30778727\n",
      "Current loss: 0.18311912\n",
      "Current loss: 0.19250679\n",
      "Current loss: 0.29742157\n",
      "Current loss: 0.43671015\n",
      "Current loss: 0.41421652\n",
      "Current loss: 0.35764533\n",
      "Current loss: 0.33696142\n",
      "Current loss: 0.16958846\n",
      "Current loss: 0.417826\n",
      "Current loss: 0.2889675\n",
      "Current loss: 0.5933707\n",
      "Current loss: 0.43883505\n",
      "Current loss: 0.35818812\n",
      "Current loss: 0.36069447\n",
      "Current loss: 0.25698233\n",
      "Current loss: 0.27006423\n",
      "Current loss: 0.344255\n",
      "Current loss: 0.28362218\n",
      "Current loss: 0.23884499\n",
      "Current loss: 0.47851598\n",
      "Current loss: 0.21357971\n",
      "Current loss: 0.24921355\n",
      "Current loss: 0.18576883\n",
      "Current loss: 0.25704083\n",
      "Current loss: 0.541294\n",
      "Current loss: 0.58453256\n",
      "Current loss: 0.3454567\n",
      "Current loss: 0.31867713\n",
      "Current loss: 0.21517277\n",
      "Current loss: 0.32571623\n",
      "Current loss: 0.21034715\n",
      "Current loss: 0.45878312\n",
      "Current loss: 0.164083\n",
      "Current loss: 0.23409009\n",
      "Current loss: 0.3856011\n",
      "Current loss: 0.26981404\n",
      "Current loss: 0.24796289\n",
      "Current loss: 0.39021516\n",
      "Current loss: 0.24706496\n",
      "Current loss: 0.2646645\n",
      "Current loss: 0.27845877\n",
      "Current loss: 0.16531406\n",
      "Current loss: 0.18502\n",
      "Current loss: 0.23582621\n",
      "Current loss: 0.2677246\n",
      "Current loss: 0.40885958\n",
      "Current loss: 0.34983936\n",
      "Current loss: 0.28521144\n",
      "Current loss: 0.19784804\n",
      "Current loss: 0.6344195\n",
      "Current loss: 0.15406136\n",
      "Current loss: 0.2769425\n",
      "Current loss: 0.43976277\n",
      "Current loss: 0.19806844\n",
      "Current loss: 0.23623979\n",
      "Current loss: 0.2603913\n",
      "Current loss: 0.20940068\n",
      "Current loss: 0.33012757\n",
      "Current loss: 0.3598768\n",
      "Current loss: 0.16925637\n",
      "Current loss: 0.23569328\n",
      "Current loss: 0.32740477\n",
      "Current loss: 0.43878654\n",
      "Current loss: 0.24569772\n",
      "Current loss: 0.21167192\n",
      "Current loss: 0.46547407\n",
      "Current loss: 0.25574806\n",
      "Current loss: 0.378479\n",
      "Current loss: 0.4433887\n",
      "Current loss: 0.3779515\n",
      "Current loss: 0.20274241\n",
      "Current loss: 0.293803\n",
      "Current loss: 0.27504238\n",
      "Current loss: 0.19312713\n",
      "Current loss: 0.45390937\n",
      "Current loss: 0.19404629\n",
      "Current loss: 0.07753084\n",
      "Current loss: 0.17306964\n",
      "Current loss: 0.21744783\n",
      "Current loss: 0.2544341\n",
      "Current loss: 0.25885236\n",
      "Current loss: 0.24022785\n",
      "Current loss: 0.21757486\n",
      "Current loss: 0.2898636\n",
      "Current loss: 0.15702026\n",
      "Current loss: 0.2846244\n",
      "Current loss: 0.30690134\n",
      "Current loss: 0.07432556\n",
      "Current loss: 0.12072757\n",
      "Current loss: 0.090943575\n",
      "Current loss: 0.11140914\n",
      "Current loss: 0.12632333\n",
      "Current loss: 0.12950608\n",
      "Current loss: 0.42298934\n",
      "Current loss: 0.4854554\n",
      "Current loss: 0.25129813\n",
      "Current loss: 0.11055132\n",
      "Current loss: 0.10334559\n",
      "Current loss: 0.13669121\n",
      "Current loss: 0.3455336\n",
      "Current loss: 0.78415287\n",
      "Current loss: 0.1541661\n",
      "Current loss: 0.03804839\n",
      "Current loss: 0.5080069\n",
      "Current loss: 0.1956873\n"
     ]
    }
   ],
   "source": [
    "let optimizer = SGD(for: model, learningRate: 0.01)\n",
    "\n",
    "for i in 0..<batches.0.count {\n",
    "    let xBatch = batches.0[i]\n",
    "                .reshaped(to: [batches.0[i].shape[0], 784])\n",
    "    let yBatch = batches.1[i]\n",
    "    \n",
    "    let preds = model(xBatch)\n",
    "    let (loss, grads) = valueWithGradient(at: model) { model -> Tensor<Float> in\n",
    "        let logits = model(xBatch)\n",
    "        return softmaxCrossEntropy(logits: logits, labels: yBatch)\n",
    "    }\n",
    "    print(\"Current loss: \\(loss)\")\n",
    "    \n",
    "    optimizer.update(&model, along: grads)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Swift",
   "language": "swift",
   "name": "swift"
  },
  "language_info": {
   "file_extension": ".swift",
   "mimetype": "text/x-swift",
   "name": "swift",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
