{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exports.e_02_MNISTLoader import loadMNIST\n",
    "from exports.e_04_DataAPI import Dataset\n",
    "from exports.e_05_Losses_Optimizers_TrainEval import make_dls\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data API so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x7f67a8497df0>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x7f673448f100>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_valid, y_valid = loadMNIST()\n",
    "train_ds, valid_ds = Dataset(x_train, y_train), Dataset(x_valid, y_valid)\n",
    "\n",
    "n_sampl, n_inp = x_train.shape\n",
    "n_out = 10\n",
    "n_hid = 50\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "make_dls(train_ds, valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrapper\n",
    "Easy access to both train and valid DataLoaders, Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--export--#\n",
    "class DataWrapper():\n",
    "    def __init__(self, train_dl, valid_dl, n_out):\n",
    "        self.train_dl, self.valid_dl, self.n_out = train_dl, valid_dl, n_out\n",
    "    \n",
    "    # @property denotes a 'get' property of the class\n",
    "    @property\n",
    "    def train_ds(self): return self.train_dl.dataset\n",
    "    \n",
    "    @property\n",
    "    def valid_ds(self): return self.valid_dl.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w = DataWrapper(*make_dls(train_ds, valid_ds, batch_size), n_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--export--#\n",
    "def SimpleModel(data_w, lr=0.3, n_hid=50):\n",
    "    n_inp, n_out = data_w.train_ds.x.shape[1], data_w.n_out\n",
    "    \n",
    "    model = nn.Sequential(nn.Linear(n_inp, n_hid), \n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(n_hid, n_out))\n",
    "    \n",
    "    return model, optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "class ModelWrapper():\n",
    "    def __init__(self, model, opt, loss_f, data_w):\n",
    "        self.model, self.opt, self.loss_f, self.data_w = model, opt, loss_f, data_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w = ModelWrapper(*SimpleModel(data_w), F.cross_entropy, data_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback Class and Job Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--export--#\n",
    "STAGES = ['begin_fit',\n",
    "          'begin_epoch',\n",
    "          'begin_batch',\n",
    "          'after_loss',\n",
    "          'after_backward',\n",
    "          'after_step',\n",
    "          'begin_valid',\n",
    "          'after_epoch',\n",
    "          'after_fit']\n",
    "\n",
    "class Callback():\n",
    "    _order = 0\n",
    "    def __getattr__(self, attr): return getattr(self.job, attr)\n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__class__.__name__\n",
    "\n",
    "class DLJob():\n",
    "    def __init__(self, callbacks=[]):\n",
    "        self.cbs, self.stop = callbacks, False\n",
    "    \n",
    "    @property\n",
    "    def opt(self): return self.mw.opt\n",
    "    @property\n",
    "    def model(self): return self.mw.model\n",
    "    @property\n",
    "    def loss_f(self): return self.mw.loss_f\n",
    "    @property\n",
    "    def data_w(self): return self.mw.data_w\n",
    "    \n",
    "    \n",
    "    def one_batch(self, xb, yb):\n",
    "        self.xb, self.yb = xb, yb\n",
    "        if not self('begin_batch'): return\n",
    "        self.pred = self.model(self.xb)\n",
    "        if not self('after_pred'): return\n",
    "        self.loss = self.loss_f(self.pred, self.yb)\n",
    "        if not self('after_loss') or not self.training: return\n",
    "        self.loss.backward()\n",
    "        if not self('after_backward'): return\n",
    "        self.opt.step()\n",
    "        if not self('after_step'): return\n",
    "        self.opt.zero_grad()\n",
    "    \n",
    "    def all_batch(self, dl):\n",
    "        self.iters = len(dl)\n",
    "        for xb, yb in dl:\n",
    "            if self.stop: break\n",
    "            self.one_batch(xb, yb)\n",
    "            self('after_batch')\n",
    "        self.stop = False\n",
    "        \n",
    "    def fit(self, epochs, model_wrapper):\n",
    "        self.epochs, self.mw = epochs, model_wrapper\n",
    "        \n",
    "        try:\n",
    "            for cb in self.cbs: cb.job = self\n",
    "            if not self('begin_fit'): return\n",
    "            for epoch in range(epochs):\n",
    "                self.epoch = epoch\n",
    "                if self('begin_epoch'): \n",
    "                    self.training = True\n",
    "                    self.model.train()\n",
    "                    self.all_batch(self.data_w.train_dl)\n",
    "                    \n",
    "                with torch.no_grad():\n",
    "                    if self('begin_valid'):\n",
    "                        self.training = False\n",
    "                        self.model.eval()\n",
    "                        self.all_batch(self.data_w.valid_dl)\n",
    "                if not self('after_epoch'): break\n",
    "                    \n",
    "        finally:\n",
    "            self('after_fit')\n",
    "            self.mw = None\n",
    "            \n",
    "            \n",
    "    def __call__(self, stage):\n",
    "        for cb in sorted(self.cbs, key=lambda x: x._order):\n",
    "            f = getattr(cb, stage, None)\n",
    "            if f and f(): return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCallback(Callback):\n",
    "    \"\"\" Stops training after 10 optimization steps. \"\"\"\n",
    "    def begin_fit(self):\n",
    "        self.job.training = True\n",
    "        self.n_iters = 0\n",
    "        \n",
    "    def after_step(self):\n",
    "        self.n_iters += 1\n",
    "        print(self.n_iters)\n",
    "        if self.n_iters>=10: self.job.stop = True\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "job = DLJob([TestCallback()])\n",
    "job.fit(1, model_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback to Get Running Average of Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--export--#\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, training):\n",
    "        self.metrics, self.training = metrics, training\n",
    "    \n",
    "    def reset(self):\n",
    "        self.tot_loss, self.count = 0., 0\n",
    "        self.tot_mets = [0.] * len(self.metrics)\n",
    "    \n",
    "    @property\n",
    "    def all_stats(self): return [self.tot_loss.item()] + self.tot_mets\n",
    "    @property\n",
    "    def avg_stats(self): return [stat/self.count for stat in self.all_stats]\n",
    "    \n",
    "    def __repr__(self):\n",
    "        if not self.count: return \"\"\n",
    "        return f'{\"train\" if self.training else \"valid\"}: {self.avg_stats}'\n",
    "    \n",
    "    def accumulate(self, job):\n",
    "        batch_size = job.xb.shape[0]\n",
    "        self.tot_loss += job.loss * batch_size\n",
    "        self.count += batch_size\n",
    "        for i, metric in enumerate(self.metrics):\n",
    "            self.tot_mets[i] += metric(job.pred, job.yb) * batch_size\n",
    "            \n",
    "class AvgStatsCB(Callback):\n",
    "    def __init__(self, metrics=[]):\n",
    "        self.train_stats, self.valid_stats = AvgStats(metrics, True), AvgStats(metrics, False)\n",
    "    \n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        \n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.training else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.job)\n",
    "    \n",
    "    def after_epoch(self):\n",
    "        print(self.train_stats)\n",
    "        print(self.valid_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print running loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--export--#\n",
    "def acc_f(pred, lab): return (torch.argmax(pred, dim=1) == lab).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [0.29554005859375, tensor(0.9106)]\n",
      "valid: [0.2020339599609375, tensor(0.9417)]\n",
      "train: [0.1687086328125, tensor(0.9496)]\n",
      "valid: [0.14223358154296875, tensor(0.9587)]\n",
      "train: [0.132412578125, tensor(0.9601)]\n",
      "valid: [0.12514912109375, tensor(0.9620)]\n",
      "train: [0.110084892578125, tensor(0.9665)]\n",
      "valid: [0.1145890625, tensor(0.9657)]\n",
      "train: [0.097337568359375, tensor(0.9693)]\n",
      "valid: [0.119880615234375, tensor(0.9633)]\n"
     ]
    }
   ],
   "source": [
    "job = DLJob([AvgStatsCB([acc_f])])\n",
    "job.fit(5, model_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 06_Callbacks.ipynb has been converted to module ./exports/e_06_Callbacks.py!\r\n"
     ]
    }
   ],
   "source": [
    "!python utils/export_notebook.py 06_Callbacks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
